{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "import time\n",
    "\n",
    "url = \"https://www.data.go.kr/index.do\"\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "searchValue = input(\"어떤 공공데이터를 찾으시나요?\")\n",
    "searchPage = input(\"수집하실 페이지 범위를 입력하세요(예: 1~4): \")\n",
    "startPage = searchPage.split(\"~\")[0]\n",
    "endPage = searchPage.split(\"~\")[1]\n",
    "\n",
    "searchInput = driver.find_element(by=By.CSS_SELECTOR, value='input[class=\"input-text\"]')\n",
    "\n",
    "searchInput.send_keys(searchValue)\n",
    "searchInput.send_keys(Keys.RETURN)\n",
    "time.sleep(5)\n",
    "driver.find_element(by=By.CSS_SELECTOR, value='button[title=\"오픈 API 더보기\"]').click()\n",
    "time.sleep(5)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(int(startPage), int(endPage) + 1):\n",
    "    print()\n",
    "    driver.find_element(by=By.XPATH, value=f'//*[@id=\"apiDataList\"]/nav/a[{i + 1}]').click()\n",
    "    time.sleep(5)  \n",
    "    contents = driver.find_elements(by=By.CSS_SELECTOR, value='div[class=\"result-list\"] ul li')\n",
    "\n",
    "    for content in contents:\n",
    "        title = content.find_element(by=By.CSS_SELECTOR, value='dt a span[class=\"title\"]').text\n",
    "        \n",
    "        info_data = content.find_elements(by=By.CSS_SELECTOR, value='div[class=\"info-data\"] p span[class=\"data\"]')\n",
    "        info_list = []\n",
    "        for info in info_data:\n",
    "            info_list.append(info.text)\n",
    "\n",
    "        keywordSelecter = content.find_elements(by=By.CSS_SELECTOR, value='div[class=\"info-data\"] p')\n",
    "        findKeyword = []\n",
    "        for keyword in keywordSelecter:\n",
    "            findKeyword.append(keyword.text)\n",
    "\n",
    "        data = {\n",
    "            'title': title,\n",
    "            'provider_organizationro': info_list[0],\n",
    "            'update_date': info_list[1],\n",
    "            'hits': int(info_list[2]),\n",
    "            'request_count': int(info_list[3]),\n",
    "            'keyword': findKeyword[4].split(\" \")[1]\n",
    "        }\n",
    "\n",
    "        data_list.append(data)\n",
    "\n",
    "with open(\"Unit5.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_list, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
